# 5 BOAS PRÁTICAS para DEVS: Dados Seguros, IA Poderosa (Sem Dor de Cabeça)

> **"O dado é o ativo mais valioso. Proteger é dever."**

---

## **1. ANONIMIZAÇÃO (Top 1 – NUNCA pule!)**  
> **Remova tudo que identifica uma pessoa.**

| Antes (Risco) | Depois (Seguro) |
|---------------|------------------|
| `nome: Ana, cpf: 123.456.789-00` | `cliente_id: 1` |
| `email: ana@empresa.com` | `email_hash: a1b2c3` |

```python
# Script de anonimização (sempre rode ANTES de IA externa)
df['cliente_id'] = range(1, len(df)+1)
df = df.drop(columns=['nome', 'cpf', 'email', 'telefone', 'endereco'])
```

---

## **2. AGREGAÇÃO (Mantenha o insight, perca o detalhe)**  
> **Use médias, totais, faixas — nunca dados brutos.**

| Ruim (Individual) | Bom (Agregado) |
|-------------------|----------------|
| "Ana (SP) comprou R$5.000" | "Média de vendas SP: R$3.800" |
| "João (RJ), 19 anos, R$1.200" | "Faixa 18-25 anos: 32% das vendas" |

> **Regra**:  
> **Se não precisa do nome/cidade individual → agregue.**

---

## **3. DADOS FICTÍCIOS / SINTÉTICOS**  
> **Crie datasets falsos com estrutura real.**

```plaintext
Prompt para IA (seguro!):
"Crie um dataset sintético com 100 vendas:
- Colunas: cliente_id, regiao, valor, produto
- Sem nomes, CPFs ou e-mails reais
- Distribuição realista (70% Sudeste, média R$2.500)"
```

> **Vantagem**:  
> Teste, protótipo, relatório → **100% seguro**.

---

## **4. REVISÃO DE TERMOS DE USO (Leia antes de clicar)**  
> **Pergunte: "O que a IA faz com meu dado?"**

| Pergunta | O que checar |
|--------|-------------|
| O dado é usado para **treinar o modelo**? | → **NÃO envie PII** |
| É apagado após **X horas**? | → Melhor se < 48h |
| Tem **DPA (Data Processing Agreement)**? | → Obrigatório para empresa |
| Acesso por **funcionários da IA**? | → Risco humano |

> **Dica**:  
> **Use ChatGPT Enterprise / Azure OpenAI com contrato** → dados não treinam modelo.

---

## **5. LOGS & MONITORAMENTO (Controle quem envia o quê)**  
> **Registre todo acesso a IA externa.**

| Ação | Como fazer |
|-----|-----------|
| **Log de envio** | `log: "Fulano enviou planilha_vendas.csv → ChatGPT em 11/11/2025"` |
| **Treinamento obrigatório** | "Só usa IA externa quem fez o curso de DataGov" |
| **Aprovação por líder** | "Envio > 100 linhas → precisa de OK do tech lead" |

> **IA interna (ChatGPT Team, Azure)** →  
> **Liberdade + segurança (sem anonimização diária).**

---

## **Checklist Rápido ANTES de Enviar para IA Externa**

```markdown
- [ ] Tem **nome, CPF, e-mail, endereço**? → **ANONIMIZE**
- [ ] Pode **agregar** (média, total, faixa)? → **FAÇA**
- [ ] Posso usar **dados fictícios**? → **CRIE**
- [ ] Li os **termos de uso** da IA? → **CONFIRME**
- [ ] Registrei no **log** quem enviou? → **SIM**
```

> **Se 1 item falhar → NÃO ENVIE.**

---

## **Prompt Padrão de Segurança (Cole em TODO prompt)**

> ```
> ANTES DE QUALQUER ANÁLISE:
> 1. **Anonimize** todos os dados PII (nome, CPF, e-mail, etc.)
> 2. **Agregue** quando possível (médias, totais, faixas)
> 3. **Use apenas dados fictícios ou anonimizados**
> 4. **Confirme por escrito**: "Nenhum dado sensível presente."
> ```

---

## **Custo x Benefício: IA Interna vs Externa**

| Opção | Custo | Segurança | Esforço Diário |
|------|------|----------|----------------|
| **IA Externa (ChatGPT)** | Grátis | Baixa | Alto (anonimizar sempre) |
| **IA Interna (Azure, Enterprise)** | Pago | Alta | Baixo (sem anonimização) |

> **Vale o investimento se seu time usa IA todo dia.**

---

## **Próximos Passos (Ação IMEDIATA)**

1. **Crie a pasta `dados_anonimos/`** no seu repo.  
2. **Adicione o script de anonimização** no `pre-process.py`.  
3. **Use dados sintéticos** no próximo teste.  
4. **Leia os termos de uso** da sua IA principal.  
5. **Monte um log simples** (Excel ou Notion) de envios.

---

# Conclusão

> **Você não precisa de um DPO. Precisa de 1 hábito:**  
> **"Dados reais? Só local. Dados seguros? Só externo."**

**Com essas 5 práticas, você:**  
- Evita multas  
- Protege clientes  
- Dorme tranquilo  
- Usa IA com poder total